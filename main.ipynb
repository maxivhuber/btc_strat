{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9e3958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.data import load_all_klines\n",
    "import pandas as pd\n",
    "\n",
    "YEARS = 4\n",
    "\n",
    "df = load_all_klines(\n",
    "    root=\"data/data/spot/monthly/klines/\",\n",
    "    interval=\"1h\",\n",
    "    range_folder=\"2017-01-01_2025-10-08\",\n",
    ")\n",
    "\n",
    "# Get all original symbols\n",
    "all_symbols = df.index.get_level_values(\"Symbol\").unique()\n",
    "\n",
    "# Compute time span per symbol\n",
    "time_spans = df.groupby(level=\"Symbol\").apply(\n",
    "    lambda g: g.index.get_level_values(\"Open Time\")[-1]\n",
    "    - g.index.get_level_values(\"Open Time\")[0]\n",
    ")\n",
    "\n",
    "min_timedelta = pd.Timedelta(days=YEARS * 365.25)\n",
    "\n",
    "# Identify valid symbols\n",
    "valid_symbols = time_spans[time_spans >= min_timedelta].index\n",
    "\n",
    "# Identify dropped symbols\n",
    "dropped_symbols = all_symbols.difference(valid_symbols)\n",
    "\n",
    "# Print dropped symbols\n",
    "print(f\"Dropped {len(dropped_symbols)} symbols (less than {YEARS} years of data):\")\n",
    "for sym in sorted(dropped_symbols):\n",
    "    span = time_spans.get(sym, pd.Timedelta(0))\n",
    "    print(f\"  {sym}: {span.days} days\")\n",
    "\n",
    "# Filter the DataFrame\n",
    "df = df[df.index.get_level_values(\"Symbol\").isin(valid_symbols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82a5125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from core.plotting import plot_z_returns\n",
    "\n",
    "df_close = df[\"Close\"].unstack(\"Symbol\")\n",
    "\n",
    "# Compute log returns for each asset:\n",
    "# r_{i,t} = ln(P_{i,t} / P_{i,t-1})\n",
    "returns = np.log(df_close / df_close.shift(1))\n",
    "\n",
    "# Compute the global (whole-period) volatility per asset:\n",
    "# σ_i = sqrt( (1 / (T-1)) * Σ_t (r_{i,t} - mean(r_i))^2 )\n",
    "# the standard deviation of returns for each coin\n",
    "global_vol = returns.std()\n",
    "\n",
    "# Volatility-normalized (z-scored) returns:\n",
    "# z_{i,t} = r_{i,t} / σ_i\n",
    "# expresses each return in units of that asset's own volatility (dimensionless)\n",
    "z_returns = returns / global_vol\n",
    "\n",
    "# Plot overlapping period of 3 Coins alongside Bitcoin\n",
    "symbols = z_returns.columns.drop(\"BTCUSDT\")\n",
    "sampled = np.random.choice(symbols, 3, replace=False)\n",
    "selected = [\"BTCUSDT\"] + sampled.tolist()\n",
    "\n",
    "plot_df = z_returns[selected].dropna(how=\"any\")\n",
    "plot_df = plot_df.asfreq(\"1h\")\n",
    "assert not plot_df.isna().any().any(), \"Unexpected NaNs after asfreq('1h')\"\n",
    "\n",
    "\n",
    "plot_z_returns(z_returns, selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbc20f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Toggle to run the computation\n",
    "run = True\n",
    "\n",
    "symbols = df.index.get_level_values(\"Symbol\").unique()\n",
    "n = len(symbols)\n",
    "correlation_matrix = np.zeros((n, n))\n",
    "\n",
    "\n",
    "def align_series(series1, series2):\n",
    "    \"\"\"Return two series aligned to their common timestamps.\"\"\"\n",
    "    common_index = series1.index.intersection(series2.index)\n",
    "    return series1.loc[common_index], series2.loc[common_index]\n",
    "\n",
    "\n",
    "if run:\n",
    "    total_combinations = n * (n - 1) // 2\n",
    "    progress_bar = tqdm(total=total_combinations, desc=\"Computing correlations\")\n",
    "\n",
    "    for i, symbol_i in enumerate(symbols):\n",
    "        data_i = df.xs(symbol_i, level=\"Symbol\")[\"Close\"]\n",
    "        for j, symbol_j in enumerate(symbols):\n",
    "            if i >= j:  # use only upper triangle\n",
    "                progress_bar.update(1 if i != j else 0)\n",
    "                continue\n",
    "\n",
    "            data_j = df.xs(symbol_j, level=\"Symbol\")[\"Close\"]\n",
    "            s1, s2 = align_series(data_i, data_j)\n",
    "\n",
    "            # Skip if no overlap\n",
    "            if s1.empty or s2.empty:\n",
    "                correlation_matrix[i, j] = np.nan\n",
    "                progress_bar.update(1)\n",
    "                continue\n",
    "\n",
    "            # Pearson correlation of CLOSE prices (or log returns if you prefer)\n",
    "            corr, _ = pearsonr(s1, s2)\n",
    "            correlation_matrix[i, j] = corr\n",
    "            progress_bar.update(1)\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    # Symmetrize and set diagonals\n",
    "    correlation_matrix = correlation_matrix + correlation_matrix.T\n",
    "    np.fill_diagonal(correlation_matrix, 1.0)\n",
    "\n",
    "    # Convert to DataFrame and save\n",
    "    correlation_df = pd.DataFrame(correlation_matrix, index=symbols, columns=symbols)\n",
    "    correlation_df.to_csv(\"correlation.csv\")\n",
    "\n",
    "    # --- 3️⃣ Heatmap plot ---\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.title(\"Correlation Matrix of Crypto Assets\")\n",
    "    plt.imshow(correlation_matrix, cmap=\"coolwarm\", interpolation=\"none\", aspect=\"auto\")\n",
    "    plt.colorbar(label=\"Pearson Correlation\")\n",
    "    plt.xticks(ticks=range(n), labels=symbols, rotation=90)\n",
    "    plt.yticks(ticks=range(n), labels=symbols)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223ee09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "correlation_df = pd.read_csv(\"correlation.csv\", index_col=\"Symbol\")\n",
    "\n",
    "abs_corr = correlation_df[\"BTCUSDT\"].abs().drop(\"BTCUSDT\")\n",
    "\n",
    "# Choose quantile threshold (e.g., keep 40% least correlated assets)\n",
    "q = 0.3\n",
    "t_corr = abs_corr.quantile(q)\n",
    "print(f\"Chosen correlation threshold (q={q:.2f}): {t_corr:.3f}\")\n",
    "\n",
    "# Assets less correlated to BTC\n",
    "less_corr_assets = abs_corr[abs_corr <= t_corr].index.tolist()\n",
    "\n",
    "# Combine BTC with less-correlated assets\n",
    "selected_symbols = [\"BTCUSDT\"] + less_corr_assets\n",
    "\n",
    "# Filter rows where 'Symbol' level is in the selected list\n",
    "df_btc_lesscorr = (\n",
    "    df.loc[df.index.get_level_values(\"Symbol\").isin(selected_symbols)]\n",
    "    .sort_index(level=[\"Symbol\", \"Open Time\"])\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Included symbols:\",\n",
    "    df_btc_lesscorr.index.get_level_values(\"Symbol\").unique().tolist(),\n",
    ")\n",
    "plot_z_returns(\n",
    "    z_returns, df_btc_lesscorr.index.get_level_values(\"Symbol\").unique().tolist()[:5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c4492c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "662f5a6c",
   "metadata": {},
   "source": [
    "#### Visualize event_density_score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e207d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from core.dc import (\n",
    "    compute_directional_change_events,\n",
    "    attach_OSV_EXT_to_runs,\n",
    "    attach_TMV_EXT_to_runs,\n",
    "    attach_T_to_runs,\n",
    "    attach_R_to_runs,\n",
    ")\n",
    "from core.opt import event_density_score\n",
    "\n",
    "# df_single = df.loc[\"BTCUSDT\"]\n",
    "\n",
    "thetas = np.linspace(0.01, 10.0, 10000)\n",
    "# prices = df_single[\"Close\"].to_numpy()\n",
    "prices = z_returns[\"BTCUSDT\"]\n",
    "\n",
    "penalty_vals, counts = [], []\n",
    "\n",
    "# Reference: d_target = 0.002 → roughly one event every 500 samples\n",
    "d_target = 0.002\n",
    "\n",
    "for theta in thetas:\n",
    "    events, runs = compute_directional_change_events(prices, theta)\n",
    "    runs = attach_TMV_EXT_to_runs(runs, theta)\n",
    "    runs = attach_OSV_EXT_to_runs(runs, theta)\n",
    "    runs = attach_T_to_runs(runs)\n",
    "    runs = attach_R_to_runs(runs, theta)\n",
    "\n",
    "    penalty_vals.append(\n",
    "        event_density_score(prices, events, d_target=d_target, alpha=2, beta=1.5)\n",
    "    )\n",
    "    counts.append(len(runs))\n",
    "\n",
    "x = thetas * 100  # percent for x‑axis (thresholds in %)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Additional “log‑space” representation\n",
    "# -------------------------------------------------------------------------\n",
    "# Convert raw penalties to a view vs. log of density ratio:\n",
    "T = len(prices)\n",
    "densities = np.array(counts) / T\n",
    "ratio = densities / d_target\n",
    "\n",
    "# Use log10 for visual readability\n",
    "log_ratio = np.log10(ratio)\n",
    "\n",
    "# Sort both lists for a visually continuous log curve\n",
    "# (optional, ensures x increases)\n",
    "sorted_idx = np.argsort(log_ratio)\n",
    "log_ratio_sorted = log_ratio[sorted_idx]\n",
    "penalty_sorted = np.array(penalty_vals)[sorted_idx]\n",
    "\n",
    "# --- Build interactive Plotly figure ---\n",
    "fig = go.Figure()\n",
    "\n",
    "# Left axis: Event‑count penalty\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x,\n",
    "        y=penalty_vals,\n",
    "        name=\"Penalty (vs θ)\",\n",
    "        mode=\"lines+markers\",\n",
    "        marker=dict(color=\"blue\"),\n",
    "        line=dict(color=\"blue\"),\n",
    "        hovertemplate=\"θ=%{x:.2f}%<br>Penalty=%{y:.4f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Additional trace: Penalty vs log10(d/d_target)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=log_ratio_sorted,\n",
    "        y=penalty_sorted,\n",
    "        name=\"Penalty (vs log₁₀ density ratio)\",\n",
    "        mode=\"lines+markers\",\n",
    "        marker=dict(color=\"green\", symbol=\"circle\"),\n",
    "        line=dict(color=\"green\", dash=\"dot\"),\n",
    "        hovertemplate=\"log₁₀(d/dₜ)=%{x:.3f}<br>Penalty=%{y:.4f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Right axis: Number of runs\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x,\n",
    "        y=counts,\n",
    "        name=\"Event count\",\n",
    "        mode=\"lines+markers\",\n",
    "        marker=dict(color=\"red\", symbol=\"square\"),\n",
    "        line=dict(color=\"red\", dash=\"dash\"),\n",
    "        yaxis=\"y2\",\n",
    "        hovertemplate=\"θ=%{x:.2f}%<br>Runs=%{y}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Layout with proper axis definitions\n",
    "fig.update_layout(\n",
    "    title=\"Event‑count penalty (left) vs Number of runs (right)\",\n",
    "    xaxis=dict(title=\"Threshold θ (%) and log₁₀(d/dₜ)\", showgrid=True),\n",
    "    yaxis=dict(\n",
    "        title=dict(text=\"Event‑count penalty\", font=dict(color=\"blue\")),\n",
    "        tickfont=dict(color=\"blue\"),\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title=dict(text=\"Number of runs\", font=dict(color=\"red\")),\n",
    "        tickfont=dict(color=\"red\"),\n",
    "        overlaying=\"y\",\n",
    "        side=\"right\",\n",
    "    ),\n",
    "    legend=dict(x=0.02, y=0.98, bgcolor=\"rgba(0,0,0,0)\"),\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9106f17c",
   "metadata": {},
   "source": [
    "## Estimate the sqash value for up_down_asymmetry\n",
    "\n",
    "### **Choosing a good `squash` (bootstrapped, multi‑coin)**\n",
    "\n",
    "1. **Run the calibration script** — it collects overshoot ratios (|OSV_EXT| / θ) for all coins and performs bootstrapped sampling.  \n",
    "   You’ll see a **distribution of squash estimates** and a **μ(test r)** stability plot.\n",
    "\n",
    "2. **Check the histogram of bootstrapped `squash` values.**  \n",
    "   - If it’s narrow and single‑peaked → calibration is stable.  \n",
    "   - The mean / median of that distribution is your global `squash`.\n",
    "\n",
    "3. **Inspect μ(test r) curves.**  \n",
    "   - If curves almost overlap → excellent stability.  \n",
    "   - If they spread widely → different coins behave differently → consider grouping or re‑running per group.\n",
    "\n",
    "4. **Use the median bootstrap result** (reported as *“Recommended global squash value”*).  \n",
    "   - Typical overshoots (around the median r) should yield μ ≈ 0.6 – 0.8.  \n",
    "   - This keeps the metric responsive but not over‑sensitive.\n",
    "\n",
    "5. **Practical rule:**  \n",
    "   - Use the single, bootstrapped global `squash` for all coins → consistent, dimensionless normalization.  \n",
    "   - Re‑run the bootstrap only if you add many new assets or regimes change noticeably.\n",
    "\n",
    "---\n",
    "\n",
    "> 💡 *Intuition:* the bootstrap automatically tests “what if I had different coins?”  \n",
    "> If the squash estimate hardly changes (small spread), you’ve found a robust universal scaling constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa228073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from core.dc import compute_directional_change_events, attach_OSV_EXT_to_runs\n",
    "\n",
    "# --- CONFIG ---------------------------------------------------------------\n",
    "sample_frac = 0.7  # fraction of coins sampled per bootstrap\n",
    "m_bootstrap = 50  # number of bootstrap iterations\n",
    "thetas = np.linspace(0.01, 0.30, 30)\n",
    "all_coins = z_returns.columns.to_list()\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "\n",
    "# --- Helper: collect |OSV_EXT| / θ ratios for one coin --------------------\n",
    "def collect_ratios(prices: np.ndarray, thetas: np.ndarray) -> np.ndarray:\n",
    "    ratios = []\n",
    "    for theta in thetas:\n",
    "        events, runs = compute_directional_change_events(prices, theta)\n",
    "        runs = attach_OSV_EXT_to_runs(runs, theta)\n",
    "        osv = np.array(\n",
    "            [r[\"OSV_EXT\"] for r in runs if r.get(\"OSV_EXT\") is not None], float\n",
    "        )\n",
    "        osv = osv[~np.isnan(osv)]\n",
    "        if osv.size == 0:\n",
    "            continue\n",
    "        ratios.extend(np.abs(osv) / theta)\n",
    "    return np.array(ratios)\n",
    "\n",
    "\n",
    "# --- 1. Collect overshoot ratios per coin ---------------------------------\n",
    "ratios_per_coin = {}\n",
    "for coin in all_coins:\n",
    "    prices = z_returns[coin].dropna().to_numpy()\n",
    "    ratios = collect_ratios(prices, thetas)\n",
    "    if ratios.size >= 100:\n",
    "        ratios_per_coin[coin] = ratios\n",
    "\n",
    "available_coins = list(ratios_per_coin.keys())\n",
    "n_total = len(available_coins)\n",
    "if n_total == 0:\n",
    "    raise ValueError(\"No valid coins with sufficient overshoot data found.\")\n",
    "\n",
    "# --- 2. Baseline: median of coin medians ----------------------------------\n",
    "coin_medians = {c: np.median(r) for c, r in ratios_per_coin.items()}\n",
    "baseline = np.median(list(coin_medians.values()))\n",
    "print(f\"\\nBaseline median of coin medians: {baseline:.2f} from {n_total} coins\")\n",
    "\n",
    "# --- 3. Bootstrap hierarchical medians ------------------------------------\n",
    "boot_squash = []\n",
    "for i in range(m_bootstrap):\n",
    "    n_sample = max(1, int(sample_frac * n_total))\n",
    "    sample = rng.choice(available_coins, size=n_sample, replace=True)\n",
    "    sample_medians = [np.median(ratios_per_coin[c]) for c in sample]\n",
    "    boot_squash.append(np.median(sample_medians))\n",
    "boot_squash = np.array(boot_squash)\n",
    "\n",
    "# --- 4. Bootstrap diagnostics ---------------------------------------------\n",
    "print(\"\\n--- Bootstrap stability ---\")\n",
    "mean_s, std_s = boot_squash.mean(), boot_squash.std()\n",
    "cv = std_s / mean_s\n",
    "print(f\"Mean squash  : {mean_s:.2f}\")\n",
    "print(f\"Std deviation: {std_s:.2f}\")\n",
    "print(f\"Coeff. of variation: {cv:.3f}\")\n",
    "\n",
    "plt.hist(boot_squash, bins=12, color=\"cornflowerblue\", edgecolor=\"k\", alpha=0.8)\n",
    "plt.axvline(mean_s, color=\"red\", linestyle=\"--\", label=\"mean\")\n",
    "plt.title(\"Bootstrap distribution of squash estimates\")\n",
    "plt.xlabel(\"Estimated squash\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- 5. μ(test_r) stability curves ----------------------------------------\n",
    "combined = np.concatenate(list(ratios_per_coin.values()))\n",
    "test_r = np.linspace(np.percentile(combined, 5), np.percentile(combined, 95), 50)\n",
    "plt.figure(figsize=(8, 5))\n",
    "for s in boot_squash:\n",
    "    plt.plot(test_r, 1 - np.exp(-test_r / s), color=\"gray\", alpha=0.3, lw=1)\n",
    "mu_mean = np.mean([1 - np.exp(-test_r / s) for s in boot_squash], axis=0)\n",
    "mu_std = np.std([1 - np.exp(-test_r / s) for s in boot_squash], axis=0)\n",
    "plt.plot(test_r, mu_mean, \"k\", lw=2, label=\"Mean μ curve\")\n",
    "plt.fill_between(\n",
    "    test_r,\n",
    "    mu_mean - mu_std,\n",
    "    mu_mean + mu_std,\n",
    "    color=\"lightgray\",\n",
    "    alpha=0.6,\n",
    "    label=\"±1σ band\",\n",
    ")\n",
    "plt.title(\"μ(test_r) stability (bootstrap over coins)\")\n",
    "plt.xlabel(\"|OSV_EXT| / θ\")\n",
    "plt.ylabel(\"μ = 1 - exp(-r/s)\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- 6. Final global squash estimate --------------------------------------\n",
    "global_squash = np.median(boot_squash)\n",
    "ci_low, ci_high = np.percentile(boot_squash, [5, 95])\n",
    "print(f\"\\n✅  Recommended global squash: {global_squash:.2f}\")\n",
    "print(f\"    90% bootstrap CI: [{ci_low:.2f}, {ci_high:.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b98cd2c",
   "metadata": {},
   "source": [
    "#### Visualize up_down_asymmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22c8318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.opt import up_down_asymmetry\n",
    "\n",
    "prices = z_returns[\"BTCUSDT\"]\n",
    "asym_vals, counts = [], []\n",
    "\n",
    "for theta in thetas:\n",
    "    # run DC segmentation and attach indicators\n",
    "    events, runs = compute_directional_change_events(prices, theta)\n",
    "    runs = attach_TMV_EXT_to_runs(runs, theta)\n",
    "    runs = attach_OSV_EXT_to_runs(runs, theta)\n",
    "    runs = attach_T_to_runs(runs)\n",
    "    runs = attach_R_to_runs(runs, theta)\n",
    "\n",
    "    # compute normalized asymmetry: returns (mu_up_norm, mu_down_norm)\n",
    "    mu_up_norm, mu_down_norm = up_down_asymmetry(runs, theta, 4)\n",
    "    # total score could be combined (for example, mean of both directions)\n",
    "    score = (mu_up_norm + mu_down_norm) / 2.0\n",
    "\n",
    "    asym_vals.append(score)\n",
    "    counts.append(len(runs))\n",
    "    print(\n",
    "        f\"θ={theta:.3f} | runs={len(runs):4d} | μ_up={mu_up_norm:.4f} | μ_down={mu_down_norm:.4f} | score={score:.4f}\"\n",
    "    )\n",
    "\n",
    "# --- 3️⃣  Build interactive Plotly figure -------------------------------\n",
    "x = thetas * 100  # percent for the x‑axis\n",
    "fig = go.Figure()\n",
    "\n",
    "# main: asymmetry score\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x,\n",
    "        y=asym_vals,\n",
    "        name=\"Up–Down Asymmetry Score (avg of μ↑, μ↓)\",\n",
    "        mode=\"lines+markers\",\n",
    "        marker=dict(color=\"dodgerblue\"),\n",
    "        line=dict(color=\"dodgerblue\"),\n",
    "        hovertemplate=\"θ = %{x:.2f}%<br>Asymmetry Score = %{y:.4f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# optional secondary trace: event count\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x,\n",
    "        y=counts,\n",
    "        name=\"Event Count\",\n",
    "        mode=\"lines+markers\",\n",
    "        marker=dict(color=\"red\", symbol=\"square\"),\n",
    "        line=dict(color=\"red\", dash=\"dash\"),\n",
    "        yaxis=\"y2\",\n",
    "        hovertemplate=\"θ = %{x:.2f}%<br>Runs = %{y}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# layout: left = score, right = event count\n",
    "fig.update_layout(\n",
    "    title=\"Normalized Up–Down Asymmetry Score (left) vs Event Count (right)\",\n",
    "    xaxis=dict(title=\"Threshold θ (%)\"),\n",
    "    yaxis=dict(\n",
    "        title=dict(text=\"Asymmetry Score [0–1]\", font=dict(color=\"dodgerblue\")),\n",
    "        tickfont=dict(color=\"dodgerblue\"),\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title=dict(text=\"Number of Runs\", font=dict(color=\"red\")),\n",
    "        tickfont=dict(color=\"red\"),\n",
    "        overlaying=\"y\",\n",
    "        side=\"right\",\n",
    "    ),\n",
    "    legend=dict(x=0.02, y=0.98, bgcolor=\"rgba(0,0,0,0)\"),\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5428d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 1️⃣  Evaluation function\n",
    "# =====================================================\n",
    "\n",
    "\n",
    "def make_evaluate_theta(prices, osv_min, osv_max, N_min, N_max, p):\n",
    "    \"\"\"\n",
    "    Create an evaluation function that DEAP can call.\n",
    "    Closes over the provided constants (data + global parameters).\n",
    "    \"\"\"\n",
    "\n",
    "    def evaluate_theta(individual):\n",
    "        θ = individual[0]\n",
    "        # --- Run DC segmentation and attach indicators -----------------\n",
    "        events, runs = compute_directional_change_events(prices, θ)\n",
    "        runs = attach_OSV_EXT_to_runs(runs, θ)\n",
    "\n",
    "        # --- Compute objectives ----------------------------------------\n",
    "        f1 = event_count_score(runs, N_min=N_min, N_max=N_max, p=p)\n",
    "        μ_up, μ_down = up_down_asymmetry(runs, osv_min, osv_max)\n",
    "        f2 = (μ_up + μ_down) / 2.0  # combine up & down components\n",
    "\n",
    "        return f1, f2  # maximize both objectives\n",
    "\n",
    "    return evaluate_theta\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 2️⃣  NSGA‑II setup / execution\n",
    "# =====================================================\n",
    "\n",
    "\n",
    "def run_nsga2(\n",
    "    prices,\n",
    "    osv_min,\n",
    "    osv_max,\n",
    "    N_min=40,\n",
    "    N_max=170,\n",
    "    p=2,\n",
    "    ngen=50,\n",
    "    pop_size=80,\n",
    "    cxpb=0.7,\n",
    "    mutpb=0.3,\n",
    "    seed=42,\n",
    "):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # --- Setup evolutionary framework -----------------\n",
    "    creator.create(\"FitnessMulti\", base.Fitness, weights=(1.0, 1.0))  # maximize both\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMulti)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_theta\", lambda: random.uniform(0.001, 0.40))\n",
    "    toolbox.register(\n",
    "        \"individual\", tools.initRepeat, creator.Individual, toolbox.attr_theta, n=1\n",
    "    )\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "    toolbox.register(\n",
    "        \"evaluate\", make_evaluate_theta(prices, osv_min, osv_max, N_min, N_max, p)\n",
    "    )\n",
    "    toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "    toolbox.register(\n",
    "        \"mutate\", tools.mutPolynomialBounded, low=0.001, up=0.40, eta=25.0, indpb=1.0\n",
    "    )\n",
    "    toolbox.register(\"select\", tools.selNSGA2)\n",
    "\n",
    "    # --- Initialize population & Hall of Fame ----------\n",
    "    pop = toolbox.population(n=pop_size)\n",
    "    hof = tools.ParetoFront()\n",
    "\n",
    "    # --- Run evolutionary loop (all keyword style) -----\n",
    "    algorithms.eaMuPlusLambda(\n",
    "        population=pop,\n",
    "        toolbox=toolbox,\n",
    "        mu=pop_size,\n",
    "        lambda_=2 * pop_size,\n",
    "        cxpb=cxpb,\n",
    "        mutpb=mutpb,\n",
    "        ngen=ngen,\n",
    "        halloffame=hof,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # --- Extract Pareto‑optimal results ----------------\n",
    "    pareto_thetas = np.array([ind[0] for ind in hof])\n",
    "    pareto_scores = np.array([ind.fitness.values for ind in hof])\n",
    "    return pareto_thetas, pareto_scores\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 3️⃣  Run optimizer\n",
    "# =====================================================\n",
    "\n",
    "prices = df[\"Close\"].to_numpy()\n",
    "\n",
    "pareto_thetas, pareto_scores = run_nsga2(\n",
    "    prices,\n",
    "    osv_min=osv_min,\n",
    "    osv_max=osv_max,\n",
    "    N_min=73,\n",
    "    N_max=220,\n",
    "    p=2,\n",
    "    cxpb=0.7,\n",
    "    mutpb=0.3,\n",
    "    ngen=40,\n",
    "    pop_size=40,\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# 4️⃣  Visualize Pareto front\n",
    "# =====================================================\n",
    "\n",
    "score_event = pareto_scores[:, 0]\n",
    "score_asym = pareto_scores[:, 1]\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(score_event, score_asym, s=50, c=pareto_thetas, cmap=\"viridis\")\n",
    "plt.xlabel(\"Event‑count score [0–1]\")\n",
    "plt.ylabel(\"Asymmetry score [0–1]\")\n",
    "plt.title(\"Pareto‑optimal front via NSGA‑II\")\n",
    "plt.colorbar(label=\"θ\")\n",
    "plt.grid(alpha=0.4)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for θ, f1, f2 in zip(pareto_thetas, score_event, score_asym):\n",
    "    print(f\"θ={θ:.4f} | event_count={f1:.4f} | asymmetry={f2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be3912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.plotting import plot_directional_change_runs\n",
    "\n",
    "theta = 0.1596\n",
    "prices = df[\"Close\"].to_numpy()\n",
    "\n",
    "events, runs = compute_directional_change_events(prices, theta)\n",
    "\n",
    "end_date = pd.Timestamp.today().normalize()\n",
    "start_date = end_date - pd.DateOffset(years=1)\n",
    "\n",
    "plot_directional_change_runs(\n",
    "    prices=prices,\n",
    "    theta=0.16,\n",
    "    events=events,\n",
    "    runs=runs,\n",
    "    datetimes=df[\"Close Time\"].to_numpy(),\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    "    mark_events=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "btc-strat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
