{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9e3958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# Binance BTC/USDT hourly data loader and cleaner\n",
    "# --------------------------------------------------------------\n",
    "# ‚Ä¢ Reads all zipped monthly 1‚Äëhour klines\n",
    "# ‚Ä¢ Detects and fixes timestamp unit inconsistencies (ms/¬µs/ns)\n",
    "# ‚Ä¢ Builds exact hourly timeline\n",
    "# ‚Ä¢ Fills small gaps (ffill) and longer gaps (log‚Äëlinear interpolation)\n",
    "# ==============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 1) Configuration\n",
    "# --------------------------------------------------------------\n",
    "path = Path(\"data/spot/monthly/klines/BTCUSDT/1h/2017-01-01_2025-10-04\")\n",
    "\n",
    "columns = [\n",
    "    \"Open Time\",\n",
    "    \"Open\",\n",
    "    \"High\",\n",
    "    \"Low\",\n",
    "    \"Close\",\n",
    "    \"Volume\",\n",
    "    \"Close Time\",\n",
    "    \"Quote Asset Volume\",\n",
    "    \"Number of Trades\",\n",
    "    \"Taker Buy Base Volume\",\n",
    "    \"Taker Buy Quote Volume\",\n",
    "    \"Ignore\",\n",
    "]\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2) Helper: detect and normalize timestamp units\n",
    "# --------------------------------------------------------------\n",
    "def normalize_timestamp_units(series: pd.Series, label: str = \"\") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Detect timestamps in milliseconds, microseconds, or nanoseconds\n",
    "    and convert everything to milliseconds.\n",
    "    Also print how many fall into each category so the totals check out.\n",
    "    \"\"\"\n",
    "    s = series.astype(float)\n",
    "\n",
    "    mask_us = s > 1e14  # likely microseconds\n",
    "    mask_ns = s > 1e17  # likely nanoseconds (rare)\n",
    "    mask_ms = ~(mask_us | mask_ns)  # the rest are milliseconds\n",
    "\n",
    "    n_total = len(s)\n",
    "    n_ms, n_us, n_ns = mask_ms.sum(), mask_us.sum(), mask_ns.sum()\n",
    "    label_str = f\" for {label}\" if label else \"\"\n",
    "    print(\n",
    "        f\"üïì Timestamp units{label_str}: \"\n",
    "        f\"{n_ms:,}‚ÄØms  |  {n_us:,}‚ÄØ¬µs  |  {n_ns:,}‚ÄØns  |  total‚ÄØ=‚ÄØ{n_total:,}\"\n",
    "    )\n",
    "\n",
    "    if n_us:\n",
    "        s.loc[mask_us] /= 1_000.0\n",
    "    if n_ns:\n",
    "        s.loc[mask_ns] /= 1_000_000.0\n",
    "    return s\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 3) Read all zipped monthly files\n",
    "# --------------------------------------------------------------\n",
    "frames = []\n",
    "for zip_path in path.glob(\"*.zip\"):\n",
    "    with zipfile.ZipFile(zip_path) as z:\n",
    "        csv_name = z.namelist()[0]\n",
    "        with z.open(csv_name) as f:\n",
    "            df = pd.read_csv(\n",
    "                f,\n",
    "                header=None,\n",
    "                names=columns,\n",
    "                dtype={\n",
    "                    \"Open Time\": \"float64\",\n",
    "                    \"Close Time\": \"float64\",\n",
    "                    \"Open\": \"float64\",\n",
    "                    \"High\": \"float64\",\n",
    "                    \"Low\": \"float64\",\n",
    "                    \"Close\": \"float64\",\n",
    "                    \"Volume\": \"float64\",\n",
    "                    \"Quote Asset Volume\": \"float64\",\n",
    "                    \"Number of Trades\": \"int32\",\n",
    "                    \"Taker Buy Base Volume\": \"float64\",\n",
    "                    \"Taker Buy Quote Volume\": \"float64\",\n",
    "                    \"Ignore\": \"float64\",\n",
    "                },\n",
    "            )\n",
    "            frames.append(df)\n",
    "\n",
    "df = pd.concat(frames, ignore_index=True)\n",
    "print(f\"\\nüì¶ Loaded {len(df):,} hourly rows\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 4) Normalize timestamps and convert to datetime\n",
    "# --------------------------------------------------------------\n",
    "df[\"Open Time\"] = normalize_timestamp_units(df[\"Open Time\"], \"Open‚ÄØTime\")\n",
    "df[\"Close Time\"] = normalize_timestamp_units(df[\"Close Time\"], \"Close‚ÄØTime\")\n",
    "\n",
    "df[\"Open Time\"] = pd.to_datetime(df[\"Open Time\"], unit=\"ms\", errors=\"coerce\")\n",
    "df[\"Close Time\"] = pd.to_datetime(df[\"Close Time\"], unit=\"ms\", errors=\"coerce\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 5) Set index, remove duplicates, regularize to 1‚Äëhour grid\n",
    "# --------------------------------------------------------------\n",
    "df = df.set_index(\"Open Time\").sort_index()\n",
    "\n",
    "if not df.index.is_unique:\n",
    "    dups = df.index.duplicated().sum()\n",
    "    print(f\"‚ö†Ô∏è  Found {dups:,} duplicate timestamps ‚Üí dropping duplicates\")\n",
    "    df = df[~df.index.duplicated(keep=\"first\")]\n",
    "\n",
    "df = df.asfreq(\"1h\")\n",
    "print(\n",
    "    f\"üïí Time range: {df.index.min()} ‚Üí {df.index.max()} | {len(df):,} rows after asfreq\"\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 6) Detect and fill missing hourly data\n",
    "# --------------------------------------------------------------\n",
    "missing_before = df.isna().any(axis=1).sum()\n",
    "if missing_before == 0:\n",
    "    print(\"\\n‚úÖ No missing hourly candles detected.\")\n",
    "else:\n",
    "    print(f\"\\nüöß Found {missing_before:,} missing hourly candles ‚Üí filling...\")\n",
    "\n",
    "    # Simple forward fill for short gaps and edges\n",
    "    df = df.ffill()\n",
    "\n",
    "    # Log‚Äëlinear interpolation for price columns\n",
    "    price_cols = [\"Open\", \"High\", \"Low\", \"Close\"]\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "    df[price_cols] = np.exp(\n",
    "        np.log(df[price_cols]).interpolate(method=\"time\", limit_direction=\"both\")\n",
    "    )\n",
    "\n",
    "    # Linear interpolation for other numeric columns\n",
    "    other_cols = num_cols.difference(price_cols)\n",
    "    df[other_cols] = df[other_cols].interpolate(method=\"time\", limit_direction=\"both\")\n",
    "\n",
    "    still_missing = df.isna().any(axis=1).sum()\n",
    "    if still_missing == 0:\n",
    "        print(\"‚úÖ All missing values filled successfully.\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"‚ö†Ô∏è  {still_missing} rows remain partially missing (likely at dataset edges).\"\n",
    "        )\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 7) Final summary\n",
    "# --------------------------------------------------------------\n",
    "print(\"\\n===== FINAL SUMMARY =====\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Time span: {df.index.min()} ‚Üí {df.index.max()}\")\n",
    "print(f\"Total hours: {len(df):,}\")\n",
    "print(f\"Columns: {df.columns}\\n\")\n",
    "print(\"\\nPreview:\")\n",
    "print(df.head(), \"\\n...\\n\", df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d78b659",
   "metadata": {},
   "source": [
    "### How to choose hyperparameters for event count score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8741ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- parameters -------------------------------------------------------------\n",
    "d = 20  # expected cycle length in days\n",
    "\n",
    "# --- dataset information ---------------------------------------------------\n",
    "start, end = df.index.min(), df.index.max()\n",
    "n_days = (end - start).days\n",
    "n_years = n_days / 365.25  # more precise year length\n",
    "\n",
    "# total expected number of DC cycles\n",
    "res = (len(df[\"Close\"]) / 24) / d  # ‚âà expected number of events\n",
    "\n",
    "print(\n",
    "    f\"If you expect one full directional‚Äëchange cycle every {d}‚ÄØdays, \"\n",
    "    f\"you‚Äôd have roughly {res:.0f}‚ÄØevents over a {n_years:.1f}‚Äëyear interval.\\n\"\n",
    ")\n",
    "\n",
    "# --- range types ------------------------------------------------------------\n",
    "range_types = {\n",
    "    # comment or delete lines for ranges you don‚Äôt want to use\n",
    "    \"narrow\": (0.8, 1.2),  # very strict bounds\n",
    "    \"medium\": (0.5, 1.5),  # balanced bounds\n",
    "    \"broad\": (0.3, 2.0),  # tolerant bounds\n",
    "}\n",
    "\n",
    "# --- compute and print derived parameters ----------------------------------\n",
    "for name, (a1, a2) in range_types.items():\n",
    "    N_min = int(a1 * res)\n",
    "    N_max = int(a2 * res)\n",
    "    print(f\"{name.capitalize()} range ‚Üí Œ±‚ÇÅ={a1}, Œ±‚ÇÇ={a2}\")\n",
    "    print(f\"  N_min={N_min:<5d} N_max={N_max:<5d} (target ~{int(res)} events)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a147929",
   "metadata": {},
   "source": [
    "### How to choose hyperparameters for up_down_asymmetry?\n",
    "the up‚Äìdown asymmetry measure has no theoretical bounds or closed‚Äëform scaling constant.\n",
    "Its magnitude depends on the realized overshoots (`OSV_EXT`) computed from\n",
    "the directional‚Äìchange segmentation, which vary strongly with the threshold‚ÄØŒ∏,\n",
    "the instrument‚Äôs volatility, and the sampling frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576f5795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.dc import compute_directional_change_events, attach_OSV_EXT_to_runs\n",
    "\n",
    "thetas = np.linspace(0.01, 0.30, 30)\n",
    "prices = df[\"Close\"].to_numpy()\n",
    "\n",
    "all_osv = []\n",
    "for theta in thetas:\n",
    "    events, runs = compute_directional_change_events(prices, theta)\n",
    "    runs = attach_OSV_EXT_to_runs(runs, theta)\n",
    "\n",
    "    # gather all overshoot values\n",
    "    all_osv.extend(r[\"OSV_EXT\"] for r in runs if r.get(\"OSV_EXT\") is not None)\n",
    "\n",
    "osv_min, osv_max = np.min(all_osv), np.max(all_osv)\n",
    "print(f\"Global OSV range across Œ∏: min={osv_min:.4f}, max={osv_max:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e207d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from core.dc import (\n",
    "    compute_directional_change_events,\n",
    "    attach_OSV_EXT_to_runs,\n",
    "    attach_TMV_EXT_to_runs,\n",
    "    attach_T_to_runs,\n",
    "    attach_R_to_runs,\n",
    ")\n",
    "from core.opt import event_count_score\n",
    "\n",
    "# thresholds from 1‚ÄØ%‚ÄØto‚ÄØ30‚ÄØ%\n",
    "thetas = np.linspace(0.01, 0.30, 30)\n",
    "prices = df[\"Close\"].to_numpy()\n",
    "\n",
    "penalty_vals, counts = [], []\n",
    "\n",
    "for theta in thetas:\n",
    "    events, runs = compute_directional_change_events(prices, theta)\n",
    "    runs = attach_TMV_EXT_to_runs(runs, theta)\n",
    "    runs = attach_OSV_EXT_to_runs(runs, theta)\n",
    "    runs = attach_T_to_runs(runs)\n",
    "    runs = attach_R_to_runs(runs, theta)\n",
    "\n",
    "    penalty_vals.append(event_count_score(runs, N_min=48, N_max=146, p=1.5))\n",
    "    counts.append(len(runs))\n",
    "    print(f\"Œ∏={theta:.3f} | runs={len(runs):4d} | penalty={penalty_vals[-1]:.4f}\")\n",
    "\n",
    "x = thetas * 100  # percent for x-axis\n",
    "\n",
    "# --- Build interactive Plotly figure ---\n",
    "fig = go.Figure()\n",
    "\n",
    "# Left axis: Event-count penalty\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x,\n",
    "        y=penalty_vals,\n",
    "        name=\"Penalty\",\n",
    "        mode=\"lines+markers\",\n",
    "        marker=dict(color=\"blue\"),\n",
    "        line=dict(color=\"blue\"),\n",
    "        hovertemplate=\"Œ∏=%{x:.2f}%<br>Penalty=%{y:.4f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Right axis: Number of runs\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x,\n",
    "        y=counts,\n",
    "        name=\"Event‚ÄØcount\",\n",
    "        mode=\"lines+markers\",\n",
    "        marker=dict(color=\"red\", symbol=\"square\"),\n",
    "        line=dict(color=\"red\", dash=\"dash\"),\n",
    "        yaxis=\"y2\",\n",
    "        hovertemplate=\"Œ∏=%{x:.2f}%<br>Runs=%{y}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Layout with proper axis definitions\n",
    "fig.update_layout(\n",
    "    title=\"Event‚Äëcount‚ÄØpenalty‚ÄØ(left)‚ÄØvs‚ÄØNumber‚ÄØof‚ÄØruns‚ÄØ(right)\",\n",
    "    xaxis=dict(title=\"Threshold‚ÄØŒ∏‚ÄØ(%)\"),\n",
    "    yaxis=dict(\n",
    "        title=dict(text=\"Event‚Äëcount‚ÄØpenalty\", font=dict(color=\"blue\")),\n",
    "        tickfont=dict(color=\"blue\"),\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title=dict(text=\"Number‚ÄØof‚ÄØruns\", font=dict(color=\"red\")),\n",
    "        tickfont=dict(color=\"red\"),\n",
    "        overlaying=\"y\",\n",
    "        side=\"right\",\n",
    "    ),\n",
    "    legend=dict(x=0.02, y=0.98, bgcolor=\"rgba(0,0,0,0)\"),\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22c8318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.opt import up_down_asymmetry\n",
    "\n",
    "asym_vals, counts = [], []\n",
    "\n",
    "for theta in thetas:\n",
    "    # run DC segmentation and attach indicators\n",
    "    events, runs = compute_directional_change_events(prices, theta)\n",
    "    runs = attach_TMV_EXT_to_runs(runs, theta)\n",
    "    runs = attach_OSV_EXT_to_runs(runs, theta)\n",
    "    runs = attach_T_to_runs(runs)\n",
    "    runs = attach_R_to_runs(runs, theta)\n",
    "\n",
    "    # compute normalized asymmetry: returns (mu_up_norm, mu_down_norm)\n",
    "    mu_up_norm, mu_down_norm = up_down_asymmetry(runs, osv_min, osv_max)\n",
    "    # total score could be combined (for example, mean of both directions)\n",
    "    score = (mu_up_norm + mu_down_norm) / 2.0\n",
    "\n",
    "    asym_vals.append(score)\n",
    "    counts.append(len(runs))\n",
    "    print(\n",
    "        f\"Œ∏={theta:.3f} | runs={len(runs):4d} | Œº_up={mu_up_norm:.4f} | Œº_down={mu_down_norm:.4f} | score={score:.4f}\"\n",
    "    )\n",
    "\n",
    "# --- 3Ô∏è‚É£  Build interactive Plotly figure -------------------------------\n",
    "x = thetas * 100  # percent for the x‚Äëaxis\n",
    "fig = go.Figure()\n",
    "\n",
    "# main: asymmetry score\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x,\n",
    "        y=asym_vals,\n",
    "        name=\"Up‚ÄìDown‚ÄØAsymmetry‚ÄØScore‚ÄØ(avg‚ÄØof‚ÄØŒº‚Üë,‚ÄØŒº‚Üì)\",\n",
    "        mode=\"lines+markers\",\n",
    "        marker=dict(color=\"dodgerblue\"),\n",
    "        line=dict(color=\"dodgerblue\"),\n",
    "        hovertemplate=\"Œ∏‚ÄØ=‚ÄØ%{x:.2f}%<br>Asymmetry‚ÄØScore‚ÄØ=‚ÄØ%{y:.4f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# optional secondary trace: event count\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x,\n",
    "        y=counts,\n",
    "        name=\"Event‚ÄØCount\",\n",
    "        mode=\"lines+markers\",\n",
    "        marker=dict(color=\"red\", symbol=\"square\"),\n",
    "        line=dict(color=\"red\", dash=\"dash\"),\n",
    "        yaxis=\"y2\",\n",
    "        hovertemplate=\"Œ∏‚ÄØ=‚ÄØ%{x:.2f}%<br>Runs‚ÄØ=‚ÄØ%{y}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# layout: left = score, right = event count\n",
    "fig.update_layout(\n",
    "    title=\"Normalized‚ÄØUp‚ÄìDown‚ÄØAsymmetry‚ÄØScore‚ÄØ(left)‚ÄØvs‚ÄØEvent‚ÄØCount‚ÄØ(right)\",\n",
    "    xaxis=dict(title=\"Threshold‚ÄØŒ∏‚ÄØ(%)\"),\n",
    "    yaxis=dict(\n",
    "        title=dict(text=\"Asymmetry‚ÄØScore‚ÄØ[0‚Äì1]\", font=dict(color=\"dodgerblue\")),\n",
    "        tickfont=dict(color=\"dodgerblue\"),\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title=dict(text=\"Number‚ÄØof‚ÄØRuns\", font=dict(color=\"red\")),\n",
    "        tickfont=dict(color=\"red\"),\n",
    "        overlaying=\"y\",\n",
    "        side=\"right\",\n",
    "    ),\n",
    "    legend=dict(x=0.02, y=0.98, bgcolor=\"rgba(0,0,0,0)\"),\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5428d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 1Ô∏è‚É£  Evaluation function\n",
    "# =====================================================\n",
    "\n",
    "\n",
    "def make_evaluate_theta(prices, osv_min, osv_max, N_min, N_max, p):\n",
    "    \"\"\"\n",
    "    Create an evaluation function that DEAP can call.\n",
    "    Closes over the provided constants (data + global parameters).\n",
    "    \"\"\"\n",
    "\n",
    "    def evaluate_theta(individual):\n",
    "        Œ∏ = individual[0]\n",
    "        # --- Run DC segmentation and attach indicators -----------------\n",
    "        events, runs = compute_directional_change_events(prices, Œ∏)\n",
    "        runs = attach_OSV_EXT_to_runs(runs, Œ∏)\n",
    "\n",
    "        # --- Compute objectives ----------------------------------------\n",
    "        f1 = event_count_score(runs, N_min=N_min, N_max=N_max, p=p)\n",
    "        Œº_up, Œº_down = up_down_asymmetry(runs, osv_min, osv_max)\n",
    "        f2 = (Œº_up + Œº_down) / 2.0  # combine up & down components\n",
    "\n",
    "        return f1, f2  # maximize both objectives\n",
    "\n",
    "    return evaluate_theta\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 2Ô∏è‚É£  NSGA‚ÄëII setup / execution\n",
    "# =====================================================\n",
    "\n",
    "\n",
    "def run_nsga2(\n",
    "    prices,\n",
    "    osv_min,\n",
    "    osv_max,\n",
    "    N_min=40,\n",
    "    N_max=170,\n",
    "    p=2,\n",
    "    ngen=50,\n",
    "    pop_size=80,\n",
    "    cxpb=0.7,\n",
    "    mutpb=0.3,\n",
    "    seed=42,\n",
    "):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # --- Setup evolutionary framework -----------------\n",
    "    creator.create(\"FitnessMulti\", base.Fitness, weights=(1.0, 1.0))  # maximize both\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMulti)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_theta\", lambda: random.uniform(0.001, 0.40))\n",
    "    toolbox.register(\n",
    "        \"individual\", tools.initRepeat, creator.Individual, toolbox.attr_theta, n=1\n",
    "    )\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "    toolbox.register(\n",
    "        \"evaluate\", make_evaluate_theta(prices, osv_min, osv_max, N_min, N_max, p)\n",
    "    )\n",
    "    toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "    toolbox.register(\n",
    "        \"mutate\", tools.mutPolynomialBounded, low=0.001, up=0.40, eta=25.0, indpb=1.0\n",
    "    )\n",
    "    toolbox.register(\"select\", tools.selNSGA2)\n",
    "\n",
    "    # --- Initialize population & Hall of Fame ----------\n",
    "    pop = toolbox.population(n=pop_size)\n",
    "    hof = tools.ParetoFront()\n",
    "\n",
    "    # --- Run evolutionary loop (all keyword style) -----\n",
    "    algorithms.eaMuPlusLambda(\n",
    "        population=pop,\n",
    "        toolbox=toolbox,\n",
    "        mu=pop_size,\n",
    "        lambda_=2 * pop_size,\n",
    "        cxpb=cxpb,\n",
    "        mutpb=mutpb,\n",
    "        ngen=ngen,\n",
    "        halloffame=hof,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # --- Extract Pareto‚Äëoptimal results ----------------\n",
    "    pareto_thetas = np.array([ind[0] for ind in hof])\n",
    "    pareto_scores = np.array([ind.fitness.values for ind in hof])\n",
    "    return pareto_thetas, pareto_scores\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 3Ô∏è‚É£  Run optimizer\n",
    "# =====================================================\n",
    "\n",
    "prices = df[\"Close\"].to_numpy()\n",
    "\n",
    "pareto_thetas, pareto_scores = run_nsga2(\n",
    "    prices,\n",
    "    osv_min=osv_min,\n",
    "    osv_max=osv_max,\n",
    "    N_min=73,\n",
    "    N_max=220,\n",
    "    p=2,\n",
    "    cxpb=0.7,\n",
    "    mutpb=0.3,\n",
    "    ngen=40,\n",
    "    pop_size=40,\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# 4Ô∏è‚É£  Visualize Pareto front\n",
    "# =====================================================\n",
    "\n",
    "score_event = pareto_scores[:, 0]\n",
    "score_asym = pareto_scores[:, 1]\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(score_event, score_asym, s=50, c=pareto_thetas, cmap=\"viridis\")\n",
    "plt.xlabel(\"Event‚Äëcount‚ÄØscore‚ÄØ[0‚Äì1]\")\n",
    "plt.ylabel(\"Asymmetry‚ÄØscore‚ÄØ[0‚Äì1]\")\n",
    "plt.title(\"Pareto‚Äëoptimal‚ÄØfront‚ÄØvia‚ÄØNSGA‚ÄëII\")\n",
    "plt.colorbar(label=\"Œ∏\")\n",
    "plt.grid(alpha=0.4)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for Œ∏, f1, f2 in zip(pareto_thetas, score_event, score_asym):\n",
    "    print(f\"Œ∏={Œ∏:.4f} | event_count={f1:.4f} | asymmetry={f2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be3912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.plotting import plot_directional_change_runs\n",
    "\n",
    "theta = 0.1596\n",
    "prices = df[\"Close\"].to_numpy()\n",
    "\n",
    "events, runs = compute_directional_change_events(prices, theta)\n",
    "\n",
    "end_date = pd.Timestamp.today().normalize()\n",
    "start_date = end_date - pd.DateOffset(years=1)\n",
    "\n",
    "plot_directional_change_runs(\n",
    "    prices=prices,\n",
    "    theta=0.16,\n",
    "    events=events,\n",
    "    runs=runs,\n",
    "    datetimes=df[\"Close Time\"].to_numpy(),\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    "    mark_events=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "btc-strat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
